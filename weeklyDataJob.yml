name: Weekly Data Job

on:
  schedule:
    - cron: "15 11 * * SAT" # every Saturday at 11:00 UTC
  workflow_dispatch: # allows manual trigger

jobs:
  run-script:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    environment: License Script   # environment with secrets

    steps:
      # Step 1: Checkout repo
      - uses: actions/checkout@v3

      # Step 2: Setup Node
      - uses: actions/setup-node@v3
        with:
          node-version: 20

      # Step 3: Install dependencies
      - name: Install npm dependencies
        run: npm ci

      # Step 4: Authenticate with GCP (optional)
      - uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}
      - uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: klett-cx-analytics

      # Step 5: Run cleanedScript.cjs
      - name: Run cleanedScript.cjs
        run: |
          echo "Starting cleanedScript.cjs..."
          node ./scripts/clean-fetch-districts.cjs
          echo "cleanedScript.cjs finished running."

      # Step 6: Debug data directory
      - name: Debug data directory
        run: |
          echo "Repo root:"
          ls -R .
          echo "Data folder:"
          ls -R data || echo "No data folder found"

      # Step 7: Wait for output file
      - name: Wait for LicenseData JSON
        run: |
          echo "Checking for LicenseData JSON..."
          ls -lh data/LicenseData_* || echo "No LicenseData file yet"

      # Step 8: Run flattenerJsonToCsv.cjs
      - name: Run flattener script
        run: |
          echo "Running flattener script..."
          node ./scripts/flattenerJsonToCsv.cjs
          echo "flattener finished running."

      # Step 9: Upload artifacts
      - name: Upload License Data
        uses: actions/upload-artifact@v4
        with:
          name: license-data
          path: |
            data/LicenseData_*.json
            data/flattened_output_*.csv
          if-no-files-found: warn
